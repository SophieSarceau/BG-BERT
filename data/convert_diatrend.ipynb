{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, getopt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import math\n",
    "import json\n",
    "from time import time\n",
    "from datetime import datetime, timedelta, time,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cgm_construction(cgm_df, bolus_df, basal_df):\n",
    "    combined_df = cgm_df\n",
    "    # add new zero columns to combined_df: 'normal', 'carbInput', 'insulinCarbRatio'\n",
    "    combined_df['normal'] = 0\n",
    "    combined_df['carbInput'] = 0\n",
    "    combined_df['insulinCarbRatio'] = 0\n",
    "    combined_df['duration'] = 0\n",
    "    combined_df['rate'] = 0\n",
    "    # go through each row of bolus_df and add the bolus data to the combined_df\n",
    "    for index, row in bolus_df.iterrows():\n",
    "        # print(row)\n",
    "        # get the subject and date of the bolus\n",
    "        time = row['time']\n",
    "        # find the closest time index in the combined_df to the bolus time\n",
    "        closest_time_index = np.argmin(abs(combined_df['time'] - time))\n",
    "        # check if the time lag between the bolus time and the closest time is less than 5 minutes\n",
    "        # if it is, add the bolus data to the combined_df\n",
    "        # else, do nothing\n",
    "        if abs(combined_df['time'][closest_time_index] - time) > timedelta(minutes=5):\n",
    "            continue\n",
    "        # print(\"time is: \", time, \"closest time is: \", combined_df['time'][closest_time_index])\n",
    "        # add the bolus data to the combined_df\n",
    "        combined_df.at[closest_time_index, 'normal'] = row['normal']\n",
    "        combined_df.at[closest_time_index, 'carbInput'] = row['carbInput']\n",
    "        combined_df.at[closest_time_index, 'insulinCarbRatio'] = row['insulinCarbRatio']\n",
    "    for index, row in basal_df.iterrows():\n",
    "        # print(row)\n",
    "        # get the subject and date of the basal\n",
    "        time = row['time']\n",
    "        # find the closest time index in the combined_df to the bolus time\n",
    "        closest_time_index = np.argmin(abs(combined_df['time'] - time))\n",
    "        # check if the time lag between the bolus time and the closest time is less than 5 minutes\n",
    "        # if it is, add the bolus data to the combined_df\n",
    "        # else, do nothing\n",
    "        if abs(combined_df['time'][closest_time_index] - time) > timedelta(minutes=5):\n",
    "            continue\n",
    "        # print(\"time is: \", time, \"closest time is: \", combined_df['time'][closest_time_index])\n",
    "        # add the bolus data to the combined_df\n",
    "        combined_df.at[closest_time_index, 'duration'] = row['duration']\n",
    "        combined_df.at[closest_time_index, 'rate'] = row['rate']\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def seperate_cgm(combined_df):\n",
    "    # seperate the combined_df into consecutive time series\n",
    "    # if the time difference between two consecutive time points is greater than 11 minutes, then it is a new time series\n",
    "    seperate_df_list = []\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    for index, row in combined_df.iterrows():\n",
    "        if index == 0:\n",
    "            continue\n",
    "        if abs(combined_df['time'][index] - combined_df['time'][index - 1]) > timedelta(minutes=21):\n",
    "            end_index = index - 1\n",
    "            if end_index - start_index == 0:\n",
    "                start_index = index\n",
    "                continue\n",
    "            seperate_df_list.append(combined_df[start_index:end_index].reset_index(drop=True))\n",
    "            start_index = index\n",
    "    # go through each time series and check if the time series needs interpolation\n",
    "    inter_seperate_df_list = []\n",
    "    for seperate_df in seperate_df_list:\n",
    "        # check the length of seperate_df\n",
    "        if seperate_df.index[-1] < 24 + 6:\n",
    "            continue\n",
    "        # change time to unix time in minutes\n",
    "        seperate_df['time'] = seperate_df['time'].apply(lambda x: x.timestamp() / 60).astype(int)\n",
    "        # subtract the first time point from all time points\n",
    "        seperate_df['time'] = seperate_df['time'] - seperate_df['time'].iloc[0]\n",
    "        # print(\"seperate_df['time'] is: \", seperate_df['time'])\n",
    "        # print(\"The length of the time series is: \", len(seperate_df))\n",
    "        # print(\"The last index is: \", seperate_df.index[-1])\n",
    "        # check if there are any missing time points\n",
    "        expected_time = 5 * seperate_df.index[-1]\n",
    "        # print(\"expected time: \", 5 * (len(seperate_df) - 1))\n",
    "        if expected_time == seperate_df['time'].iloc[-1]:\n",
    "            # replace nan with 0\n",
    "            seperate_df = seperate_df.fillna(0)\n",
    "            inter_seperate_df_list.append(seperate_df)\n",
    "            # print(\"no interpolation needed\")\n",
    "            # if math.isnan(list(seperate_df['time'])[-1]):\n",
    "            #     print(\"nan in seperate_df['time']\")\n",
    "            #     print(\"seperate_df['time'] is: \", seperate_df['time'])\n",
    "            # print(\"expected time: \", seperate_df['time'])\n",
    "            continue\n",
    "        else:\n",
    "            expected_time = np.array(np.arange(0, expected_time + 1, 5), dtype=int)\n",
    "            # print(\"expected time: \", expected_time)\n",
    "            inter_seperate_df = pd.DataFrame({'time': expected_time})\n",
    "            # print(\"interpolation needed\")\n",
    "            inter_seperate_df['mg/dl'] = np.interp(expected_time, seperate_df['time'], seperate_df['mg/dl'])\n",
    "            # use linear interpolation to fill in mg/dl\n",
    "            # add nan for the missing bolus data\n",
    "            inter_seperate_df['normal'] = 0\n",
    "            inter_seperate_df['carbInput'] = 0\n",
    "            inter_seperate_df['insulinCarbRatio'] = 0\n",
    "            inter_seperate_df['duration'] = 0\n",
    "            inter_seperate_df['rate'] = 0\n",
    "            # add the bolus data to the interpolated dataframe according to the time stamp\n",
    "            for index, row in seperate_df.iterrows():\n",
    "                if int(row['time'] / 5) > inter_seperate_df.index[-1]:\n",
    "                    continue\n",
    "                inter_seperate_df.at[int(row['time'] / 5), 'normal'] = row['normal']\n",
    "                inter_seperate_df.at[int(row['time'] / 5), 'carbInput'] = row['carbInput']\n",
    "                inter_seperate_df.at[int(row['time'] / 5), 'insulinCarbRatio'] = row['insulinCarbRatio']\n",
    "                inter_seperate_df.at[int(row['time'] / 5), 'duration'] = row['duration']\n",
    "                inter_seperate_df.at[int(row['time'] / 5), 'rate'] = row['rate']\n",
    "\n",
    "            # add subject to the interpolated dataframe\n",
    "            inter_seperate_df['subject'] = seperate_df['subject'][0]\n",
    "            # replace nan with 0\n",
    "            inter_seperate_df = inter_seperate_df.fillna(0)\n",
    "            # if math.isnan(list(inter_seperate_df['time'])[-1]):\n",
    "            #     print(\"nan in inter_seperate_df['time']\")\n",
    "            #     print(\"extected time is: \", expected_time)\n",
    "            #     print(\"inter_seperate_df['time'] is: \", inter_seperate_df['time'])\n",
    "            inter_seperate_df_list.append(inter_seperate_df)\n",
    "\n",
    "    # print(\"number of time series: \", len(seperate_df_list))\n",
    "    return inter_seperate_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-24 11:30:26+00:00 2019-06-24 10:31:46+00:00\n",
      "done with Subject36.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-20 14:15:45+00:00 2019-11-20 12:03:18+00:00\n",
      "done with Subject37.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-02 12:23:32+00:00 2019-07-02 02:57:45+00:00\n",
      "done with Subject29.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-25 16:56:14+00:00 2019-06-25 12:11:03+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject42.xlsx\n",
      "2019-07-09 12:36:41+00:00 2019-07-09 03:49:12+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject54.xlsx\n",
      "2019-07-31 14:33:53+00:00 2019-07-31 11:36:28+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject51.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-11 12:38:02+00:00 2019-10-11 12:37:24+00:00\n",
      "done with Subject45.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-21 18:45:34+00:00 2019-11-20 18:30:50+00:00\n",
      "done with Subject30.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-10 11:22:29+00:00 2019-10-10 09:20:46+00:00\n",
      "done with Subject46.xlsx\n",
      "2019-08-09 16:12:33+00:00 2019-08-09 13:18:18+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject47.xlsx\n",
      "2019-08-12 12:59:21+00:00 2019-08-12 12:09:22+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject49.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-22 17:10:11+00:00 2019-11-22 16:39:14+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject38.xlsx\n",
      "2019-09-22 11:20:03+00:00 2019-09-22 09:26:16+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject52.xlsx\n",
      "2019-09-27 15:34:45+00:00 2019-09-27 14:09:19+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject53.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-25 17:24:35+00:00 2019-06-25 10:30:21+00:00\n",
      "done with Subject31.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-17 13:20:03+00:00 2019-06-17 09:35:57+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject39.xlsx\n",
      "2019-09-26 09:47:39+00:00 2019-09-26 00:18:33+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695390/1061370784.py:17: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:31: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_3695390/1061370784.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with Subject50.xlsx\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './sensor-data'\n",
    "cleaned_files = os.listdir(dataset_path)\n",
    "\n",
    "# Read in CGM data\n",
    "cbg_df = pd.DataFrame()\n",
    "subject = []\n",
    "for file in cleaned_files:\n",
    "    if \"._\" in file:\n",
    "        continue\n",
    "    if \".xlsx\" not in file:\n",
    "        continue\n",
    "    # if the xlsx does not have Basal sheet, skip it\n",
    "    if \"Basal\" not in pd.ExcelFile(dataset_path + \"/\" + file).sheet_names:\n",
    "        continue\n",
    "    cgm_df = pd.read_excel(dataset_path + \"/\" + file, sheet_name='CGM')\n",
    "    # convert timestamps to mins\n",
    "    cgm_df['time'] = pd.to_datetime(cgm_df['date'], utc=True, infer_datetime_format=True)\n",
    "    # delete df['date']\n",
    "    cgm_df = cgm_df[['time', 'mg/dl']]\n",
    "    unique_cgm_df = cgm_df.drop_duplicates(subset=['time'])\n",
    "    new_cgm_df = unique_cgm_df.dropna(subset=['time'])\n",
    "    new_cgm_df['subject'] = file.replace('.xlsx', '').replace('Subject', '')\n",
    "    # check if data is ordered by time\n",
    "    if new_cgm_df['time'][0] >= new_cgm_df['time'][1]:\n",
    "        # turn the df upside down\n",
    "        new_cgm_df = new_cgm_df.iloc[::-1]\n",
    "    # delete df index\n",
    "    new_cgm_df = new_cgm_df.reset_index(drop=True)\n",
    "\n",
    "    bolus_df = pd.read_excel(dataset_path + \"/\" + file, sheet_name='Bolus')\n",
    "    bolus_df['time'] = pd.to_datetime(bolus_df['date'], utc=True, infer_datetime_format=True)\n",
    "    bolus_df = bolus_df[['time', 'normal', 'carbInput', 'insulinCarbRatio']]\n",
    "    unique_bolus_df = bolus_df.drop_duplicates(subset=['time'])\n",
    "    new_bolus_df = unique_bolus_df.dropna(subset=['time'])\n",
    "    new_bolus_df['subject'] = file.replace('.xlsx', '').replace('Subject', '')\n",
    "    # check if data is ordered by time\n",
    "    if new_bolus_df['time'][0] >= new_bolus_df['time'][1]:\n",
    "        # turn the df upside down\n",
    "        print(new_bolus_df['time'][0], new_bolus_df['time'][1])\n",
    "        new_bolus_df = new_bolus_df.iloc[::-1]\n",
    "    # delete df index\n",
    "    new_bolus_df = new_bolus_df.reset_index(drop=True)\n",
    "\n",
    "    basal_df = pd.read_excel(dataset_path + \"/\" + file, sheet_name='Basal')\n",
    "    basal_df['time'] = pd.to_datetime(basal_df['date'], utc=True, infer_datetime_format=True)\n",
    "    basal_df = basal_df[['time', 'duration', 'rate']]\n",
    "    unique_basal_df = basal_df.drop_duplicates(subset=['time'])\n",
    "    new_basal_df = unique_basal_df.dropna(subset=['time'])\n",
    "    new_basal_df['subject'] = file.replace('.xlsx', '').replace('Subject', '')\n",
    "    # check if data is ordered by time\n",
    "    if new_basal_df['time'][0] >= new_basal_df['time'][1]:\n",
    "        # turn the df upside down\n",
    "        new_basal_df = new_basal_df.iloc[::-1]\n",
    "    # delete df index\n",
    "    new_basal_df = new_basal_df.reset_index(drop=True)\n",
    "\n",
    "    # # Combine CGM and Bolus data\n",
    "    combined_df = cgm_construction(new_cgm_df, new_bolus_df, new_basal_df)\n",
    "    # move subject to the last column\n",
    "    combined_df = combined_df[['time', 'mg/dl', 'normal', 'carbInput', 'insulinCarbRatio', 'duration', 'rate', 'subject']]\n",
    "\n",
    "    # print(seperate_df_list)\n",
    "    # seperate the combined_df into test, test sets (80%, 20%)\n",
    "    train_df = combined_df.iloc[:int((combined_df.index[-1]+1) * 0.8)]\n",
    "    test_df = combined_df.iloc[int((combined_df.index[-1]+1) * 0.8):]\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    # seperate the dfs into consecutive time series\n",
    "    train_df_list = seperate_cgm(train_df)\n",
    "    test_df_list = seperate_cgm(test_df)\n",
    "\n",
    "    # print(\"train_df_list: \\n\", train_df_list)\n",
    "    # print(\"test_df_list: \\n\", test_df_list)\n",
    "    for i in range(len(train_df_list)):\n",
    "        joblib.dump(train_df_list[i], './uniform_data_baseline/' + 'subject' + train_df_list[i]['subject'][0] + '_train_' + str(i) + '.pkl')\n",
    "    for i in range(len(test_df_list)):\n",
    "        joblib.dump(test_df_list[i], './uniform_data_baseline/' + 'subject' + test_df_list[i]['subject'][0] + '_test_' + str(i) + '.pkl')\n",
    "    print(\"done with \" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset for our model\n",
    "data = ['cgm', 'bolus iob', 'carb absoption curv', 'insulin carb ratio', 'basal iob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train time series:  422\n",
      "number of test time series:  111\n"
     ]
    }
   ],
   "source": [
    "# load the train and test data from the uniform_data_baseline folder\n",
    "files = os.listdir('./uniform_data_baseline')\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "\n",
    "for file in files:\n",
    "    if \"train\" in file and '.pkl' in file:\n",
    "        train_df_list.append(joblib.load('./uniform_data_baseline/' + file))\n",
    "    if \"test\" in file and '.pkl' in file:\n",
    "        test_df_list.append(joblib.load('./uniform_data_baseline/' + file))\n",
    "print(\"number of train time series: \", len(train_df_list))\n",
    "print(\"number of test time series: \", len(test_df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use bolus insulin on board to fill in the bolus data\n",
    "def iobCalcExponential(insulin, t, dia, peak):\n",
    "    peak = 50\n",
    "    end = dia * 60\n",
    "    activityContrib = 0\n",
    "    minsAgo = t\n",
    "    iobContrib = 0\n",
    "    if minsAgo < end:\n",
    "        tau = peak * (1 - peak / end) / (1 - 2 * peak / end) # time constant of exponential decay\n",
    "        a = 2 * tau / end # rise time factor\n",
    "        S = 1 / (1 - a + (1 + a) * math.exp(-end / tau)) # auxiliary scale factor\n",
    "\n",
    "    activityContrib = insulin * (S / tau ** 2) * minsAgo * (1 - minsAgo / end) * math.exp(-minsAgo / tau)\n",
    "    # iobContrib = insulin * (1 - S * (1 - a) * ((minsAgo ** 2 / (tau * end * (1 - a)) - minsAgo / tau - 1) * math.exp(-minsAgo / tau) + 1))\n",
    "    #print('DIA:', dia, 'minsAgo:', minsAgo, 'end:', end, 'peak:', peak, 'tau:', tau, 'a:', a, 'S:', S, 'activityContrib:', activityContrib, 'iobContrib:', iobContrib)\n",
    "\n",
    "    return activityContrib\n",
    "\n",
    "# use carb absoption curv to fill in the carb data\n",
    "def carbAbsobCurv(carbintake, t):\n",
    "    if t >= 0 and t < 15:\n",
    "        return carbintake * (0.05 + 1 / 3 * t)\n",
    "    elif t >= 15 and t < 45:\n",
    "        return carbintake * (0.05 + 5 * (45 - t) / 30)\n",
    "    elif t >= 45 and t <= 240:\n",
    "        return carbintake * 0.05\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the data\n",
    "processed_train_df_list = []\n",
    "processed_test_df_list = []\n",
    "\n",
    "for train_df in train_df_list:\n",
    "    train_df = np.array(train_df)[:, 1:]\n",
    "    processed_train_df = np.zeros((len(train_df), 5)) # ['cgm', 'bolus iob', 'carb absoption curv', 'insulin carb ratio', 'basal iob']\n",
    "    processed_train_df[:, 0] = train_df[:, 0] # fill in the cgm data\n",
    "    # fill in the bolus data\n",
    "    new_bolus_iob = []\n",
    "    for i in range(len(train_df)):\n",
    "        if train_df[i][1] != 0:\n",
    "            bolus_array = np.zeros((len(train_df)))\n",
    "            for j in range(i, min(i + int(240 / 5) - 1, len(train_df))):\n",
    "                bolus_array[j] = iobCalcExponential(train_df[i][1], (j - i) * 5, 4, 50)\n",
    "            new_bolus_iob.append(bolus_array)\n",
    "    # add bolus iob into one array\n",
    "    new_bolus_iob = np.array(new_bolus_iob)\n",
    "    # print(new_bolus_iob.shape)\n",
    "    new_bolus_iob = np.sum(new_bolus_iob, axis=0)\n",
    "    # print(new_bolus_iob.shape)\n",
    "    processed_train_df[:, 1] = new_bolus_iob\n",
    "    # fill in the carb data\n",
    "    new_carb_absob_curv = []\n",
    "    for i in range(len(train_df)):\n",
    "        if train_df[i][2] != 0:\n",
    "            carb_array = np.zeros((len(train_df)))\n",
    "            for j in range(i, min(i + int(240 / 5) - 1, len(train_df))):\n",
    "                carb_array[j] = carbAbsobCurv(train_df[i][2], (j - i) * 5)\n",
    "            new_carb_absob_curv.append(carb_array)\n",
    "    # add carb absoption curv into one array\n",
    "    new_carb_absob_curv = np.array(new_carb_absob_curv)\n",
    "    # print(new_carb_absob_curv.shape)\n",
    "    new_carb_absob_curv = np.sum(new_carb_absob_curv, axis=0)\n",
    "    # print(new_carb_absob_curv.shape)\n",
    "    processed_train_df[:, 2] = new_carb_absob_curv\n",
    "    # fill in the insulin carb ratio\n",
    "    # use forward imputation\n",
    "    for i in range(len(train_df)):\n",
    "        if train_df[i][3] != 0:\n",
    "            for j in range(i, min(i + int(240 / 5) - 1, len(train_df))):\n",
    "                processed_train_df[j][3] = train_df[i][3]\n",
    "    # fill in the basal data\n",
    "    # use forward imputation according to the duration\n",
    "    for i in range(len(train_df)):\n",
    "        if train_df[i][5] != 0:\n",
    "            for j in range(i, min(i + int(train_df[i][4] / 5) - 1, len(train_df))):\n",
    "                processed_train_df[j][4] = train_df[i][5]\n",
    "    processed_train_df_list.append(processed_train_df)\n",
    "\n",
    "for test_df in test_df_list:\n",
    "    test_df = np.array(test_df)[:, 1:]\n",
    "    processed_test_df = np.zeros((len(test_df), 5)) # ['cgm', 'bolus iob', 'carb absoption curv', 'insulin carb ratio', 'basal iob']\n",
    "    processed_test_df[:, 0] = test_df[:, 0] # fill in the cgm data\n",
    "    # fill in the bolus data\n",
    "    new_bolus_iob = []\n",
    "    for i in range(len(test_df)):\n",
    "        if test_df[i][1] != 0:\n",
    "            bolus_array = np.zeros((len(test_df)))\n",
    "            for j in range(i, min(i + int(240 / 5) - 1, len(test_df))):\n",
    "                bolus_array[j] = iobCalcExponential(test_df[i][1], (j - i) * 5, 4, 50)\n",
    "            new_bolus_iob.append(bolus_array)\n",
    "    # add bolus iob into one array\n",
    "    new_bolus_iob = np.array(new_bolus_iob)\n",
    "    # print(new_bolus_iob.shape)\n",
    "    new_bolus_iob = np.sum(new_bolus_iob, axis=0)\n",
    "    # print(new_bolus_iob.shape)\n",
    "    processed_test_df[:, 1] = new_bolus_iob\n",
    "    # fill in the carb data\n",
    "    new_carb_absob_curv = []\n",
    "    for i in range(len(test_df)):\n",
    "        if test_df[i][2] != 0:\n",
    "            carb_array = np.zeros((len(test_df)))\n",
    "            for j in range(i, min(i + int(240 / 5) - 1, len(test_df))):\n",
    "                carb_array[j] = carbAbsobCurv(test_df[i][2], (j - i) * 5)\n",
    "            new_carb_absob_curv.append(carb_array)\n",
    "    # add carb absoption curv into one array\n",
    "    new_carb_absob_curv = np.array(new_carb_absob_curv)\n",
    "    # print(new_carb_absob_curv.shape)\n",
    "    new_carb_absob_curv = np.sum(new_carb_absob_curv, axis=0)\n",
    "    # print(new_carb_absob_curv.shape)\n",
    "    processed_test_df[:, 2] = new_carb_absob_curv\n",
    "    # fill in the insulin carb ratio\n",
    "    # use forward imputation\n",
    "    for i in range(len(test_df)):\n",
    "        if test_df[i][3] != 0:\n",
    "            for j in range(i, min(i + int(240 / 5) - 1, len(test_df))):\n",
    "                processed_test_df[j][3] = test_df[i][3]\n",
    "    # fill in the basal data\n",
    "    # use forward imputation according to the duration\n",
    "    for i in range(len(test_df)):\n",
    "        if test_df[i][5] != 0:\n",
    "            for j in range(i, min(i + int(test_df[i][4] / 5) - 1, len(test_df))):\n",
    "                processed_test_df[j][4] = test_df[i][5]\n",
    "    processed_test_df_list.append(processed_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data based on given backcast_length and forecast_length\n",
    "backcast_length = 24\n",
    "forecast_length = 6\n",
    "\n",
    "final_train_df_list = []\n",
    "final_test_df_list = []\n",
    "\n",
    "for train_df in processed_train_df_list:\n",
    "    for i in range(len(train_df) - backcast_length - forecast_length + 1):\n",
    "        final_train_df_list.append(train_df[i:i + backcast_length + forecast_length])\n",
    "for test_df in processed_test_df_list:\n",
    "    for i in range(len(test_df) - backcast_length - forecast_length + 1):\n",
    "        final_test_df_list.append(test_df[i:i + backcast_length + forecast_length])\n",
    "\n",
    "final_train_df_list = np.array(final_train_df_list)\n",
    "final_test_df_list = np.array(final_test_df_list)\n",
    "# split train into train and val\n",
    "train_df_list = final_train_df_list[:int(len(final_train_df_list) * 0.8)]\n",
    "val_df_list = final_train_df_list[int(len(final_train_df_list) * 0.8):]\n",
    "test_df_list = final_test_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train time series:  220574\n",
      "number of val time series:  55144\n",
      "number of test time series:  58411\n"
     ]
    }
   ],
   "source": [
    "print(\"number of train time series: \", len(train_df_list))\n",
    "print(\"number of val time series: \", len(val_df_list))\n",
    "print(\"number of test time series: \", len(test_df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data in npy format\n",
    "np.save('./uniform_data_30/train.npy', train_df_list)\n",
    "np.save('./uniform_data_30/val.npy', val_df_list)\n",
    "np.save('./uniform_data_30/test.npy', test_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data based on given backcast_length and forecast_length\n",
    "backcast_length = 48\n",
    "forecast_length = 12\n",
    "\n",
    "final_train_df_list = []\n",
    "final_test_df_list = []\n",
    "\n",
    "for train_df in processed_train_df_list:\n",
    "    if len(train_df) < backcast_length + forecast_length:\n",
    "        continue\n",
    "    for i in range(len(train_df) - backcast_length - forecast_length + 1):\n",
    "        final_train_df_list.append(train_df[i:i + backcast_length + forecast_length])\n",
    "for test_df in processed_test_df_list:\n",
    "    if len(test_df) < backcast_length + forecast_length:\n",
    "        continue\n",
    "    for i in range(len(test_df) - backcast_length - forecast_length + 1):\n",
    "        final_test_df_list.append(test_df[i:i + backcast_length + forecast_length])\n",
    "\n",
    "final_train_df_list = np.array(final_train_df_list)\n",
    "final_test_df_list = np.array(final_test_df_list)\n",
    "# split train into train and val\n",
    "train_df_list = final_train_df_list[:int(len(final_train_df_list) * 0.8)]\n",
    "val_df_list = final_train_df_list[int(len(final_train_df_list) * 0.8):]\n",
    "test_df_list = final_test_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train time series:  211081\n",
      "number of val time series:  52771\n",
      "number of test time series:  55240\n"
     ]
    }
   ],
   "source": [
    "print(\"number of train time series: \", len(train_df_list))\n",
    "print(\"number of val time series: \", len(val_df_list))\n",
    "print(\"number of test time series: \", len(test_df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data in npy format\n",
    "np.save('./uniform_data_60/train.npy', train_df_list)\n",
    "np.save('./uniform_data_60/val.npy', val_df_list)\n",
    "np.save('./uniform_data_60/test.npy', test_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glucose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
